{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPcAsY3A6/wo9T4Ctkznvym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71168dc7c14a4ea499d1db1361700905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_331a491dca7042479e919b7b5f3d5a42",
              "IPY_MODEL_ad2dc63c0c40421bbf65b1aa2e8136e1",
              "IPY_MODEL_483a843f12cb4084a159b2be60e40a37"
            ],
            "layout": "IPY_MODEL_19f387042f354f4baba96ae7110646bc"
          }
        },
        "331a491dca7042479e919b7b5f3d5a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34882878d7914f8aa292819ac626d77c",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ef0fd1ef1e4af98e0b011f72e63ff1",
            "value": "config.json: 100%"
          }
        },
        "ad2dc63c0c40421bbf65b1aa2e8136e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daf622dc158c41e49ee5baa8aba6fb1e",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5af16e71149f4cf5b9afd27875efc6d0",
            "value": 662
          }
        },
        "483a843f12cb4084a159b2be60e40a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c7b52578cb466e87252ff668665b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d311c984b84a18b8a0df907f6ee2df",
            "value": " 662/662 [00:00&lt;00:00, 42.3kB/s]"
          }
        },
        "19f387042f354f4baba96ae7110646bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34882878d7914f8aa292819ac626d77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ef0fd1ef1e4af98e0b011f72e63ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daf622dc158c41e49ee5baa8aba6fb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af16e71149f4cf5b9afd27875efc6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91c7b52578cb466e87252ff668665b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d311c984b84a18b8a0df907f6ee2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e4d5102194f46fba49f2fb2a55de465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d54e62a964304dc2a34d42e09b77b3cb",
              "IPY_MODEL_feaddd9ecbf84b87ac81d6b50e8030eb",
              "IPY_MODEL_3c106116180b4498b880cf8f7ee543a3"
            ],
            "layout": "IPY_MODEL_f67b6ba9cc5d4ec58fd2423ca86b7778"
          }
        },
        "d54e62a964304dc2a34d42e09b77b3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deef854c9a6b4117a9dbbf65d2a443a7",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd59197cc7a4962a8ef56eab3a5e6f2",
            "value": "model.safetensors: 100%"
          }
        },
        "feaddd9ecbf84b87ac81d6b50e8030eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a547603572c24e668dc90d044651442c",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac5d22f0ed1545baa3630b3fe535ba73",
            "value": 3132668804
          }
        },
        "3c106116180b4498b880cf8f7ee543a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e36e7e743ec48409b42a03e6a627604",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f17d11cfad4d0d8b1b184d93e87ebe",
            "value": " 3.13G/3.13G [00:14&lt;00:00, 231MB/s]"
          }
        },
        "f67b6ba9cc5d4ec58fd2423ca86b7778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deef854c9a6b4117a9dbbf65d2a443a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd59197cc7a4962a8ef56eab3a5e6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a547603572c24e668dc90d044651442c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5d22f0ed1545baa3630b3fe535ba73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e36e7e743ec48409b42a03e6a627604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f17d11cfad4d0d8b1b184d93e87ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de631d9dc2543809c5b39192288102b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c07a0d3e2884d22879017fa20472799",
              "IPY_MODEL_0a1a2897d8264828905ea2312260a795",
              "IPY_MODEL_5c48ab044b7f47639a5b98966563974c"
            ],
            "layout": "IPY_MODEL_2b9370748da145dc8eaf420c214dd543"
          }
        },
        "4c07a0d3e2884d22879017fa20472799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fbe1c13231648efbf0caaaa99cb3cc9",
            "placeholder": "​",
            "style": "IPY_MODEL_6cbf93df1f1a497e836c18b1860799ed",
            "value": "generation_config.json: 100%"
          }
        },
        "0a1a2897d8264828905ea2312260a795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f98582932854d208422fb0040370dd3",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8c3caa287c24ebebb859bd7b3ecd217",
            "value": 147
          }
        },
        "5c48ab044b7f47639a5b98966563974c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413032f0891841d5a685232f1f6035d4",
            "placeholder": "​",
            "style": "IPY_MODEL_9f532afdcdad4c9fad9b9e2c626a02ab",
            "value": " 147/147 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "2b9370748da145dc8eaf420c214dd543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fbe1c13231648efbf0caaaa99cb3cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cbf93df1f1a497e836c18b1860799ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f98582932854d208422fb0040370dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c3caa287c24ebebb859bd7b3ecd217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "413032f0891841d5a685232f1f6035d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f532afdcdad4c9fad9b9e2c626a02ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69fd299b35a0485f9a53d023cb697397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f227bba590d845b8ae0d314a94a6f033",
              "IPY_MODEL_37f528be0b10428ba1abe1112eae54c9",
              "IPY_MODEL_f7b768d6d27a456c96558190157cc1e0"
            ],
            "layout": "IPY_MODEL_cbf65a585e3e412b9642d3cfd86e4252"
          }
        },
        "f227bba590d845b8ae0d314a94a6f033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baebaf8d393d4035abd5184b7f061270",
            "placeholder": "​",
            "style": "IPY_MODEL_5b80bc1ac69b4f229fd0b05b02cffc75",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "37f528be0b10428ba1abe1112eae54c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f5296d300f242f29abe97359930d5c6",
            "max": 2539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_249b31f291964cdca9ea7b52e9a20b1c",
            "value": 2539
          }
        },
        "f7b768d6d27a456c96558190157cc1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc65d8705464cd2a70b4c5415c227b9",
            "placeholder": "​",
            "style": "IPY_MODEL_7aa42afd03054a5982725d7a09690e99",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 217kB/s]"
          }
        },
        "cbf65a585e3e412b9642d3cfd86e4252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baebaf8d393d4035abd5184b7f061270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b80bc1ac69b4f229fd0b05b02cffc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f5296d300f242f29abe97359930d5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249b31f291964cdca9ea7b52e9a20b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdc65d8705464cd2a70b4c5415c227b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa42afd03054a5982725d7a09690e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8160a020a3d344099739e2ad957b751e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1ebf747ae941f38f5096db0c13f876",
              "IPY_MODEL_eae0920980344645a41ca5ccd736851a",
              "IPY_MODEL_c74c1fa4de134a48b6d2fbe124aaf11b"
            ],
            "layout": "IPY_MODEL_07bc1514b4cb444e89f9c053bc609d08"
          }
        },
        "0b1ebf747ae941f38f5096db0c13f876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad7253ba3214af38c3817d91e5de1ae",
            "placeholder": "​",
            "style": "IPY_MODEL_80aa81ad70994a2abc125eacd3cf835b",
            "value": "spiece.model: 100%"
          }
        },
        "eae0920980344645a41ca5ccd736851a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_164f25e4f0114219856fdc90e7b0b335",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1c26f3be1c04ccaaa8448c266d796ee",
            "value": 791656
          }
        },
        "c74c1fa4de134a48b6d2fbe124aaf11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18e349512f84bd5a396b307e0b18645",
            "placeholder": "​",
            "style": "IPY_MODEL_3481ba895a5d4913a9c2a44150797ebf",
            "value": " 792k/792k [00:00&lt;00:00, 54.6MB/s]"
          }
        },
        "07bc1514b4cb444e89f9c053bc609d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad7253ba3214af38c3817d91e5de1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80aa81ad70994a2abc125eacd3cf835b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "164f25e4f0114219856fdc90e7b0b335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c26f3be1c04ccaaa8448c266d796ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a18e349512f84bd5a396b307e0b18645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3481ba895a5d4913a9c2a44150797ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "106fd5c0fa7b4a1c9b12b0d70c8d702b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be24dcd89e7240e5a450e9675d18ea67",
              "IPY_MODEL_59474c5b9c5e4cc897f824660b77b24d",
              "IPY_MODEL_9a780c09d7de447cbc7389599c09f106"
            ],
            "layout": "IPY_MODEL_94130dbb87794260bd7b0cd9d549661f"
          }
        },
        "be24dcd89e7240e5a450e9675d18ea67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a5c506ab224e399b99ba3acecf4031",
            "placeholder": "​",
            "style": "IPY_MODEL_427ce94033f843df889e0ba258b817a6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "59474c5b9c5e4cc897f824660b77b24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06711a453bae4337a605c36f79d25f95",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_043616c7eaf0436585d4217b253e263d",
            "value": 2201
          }
        },
        "9a780c09d7de447cbc7389599c09f106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86abbef46a844bf5b81f9bf1caf96478",
            "placeholder": "​",
            "style": "IPY_MODEL_1703a431ba5442d1b88cb6bd29a28556",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 157kB/s]"
          }
        },
        "94130dbb87794260bd7b0cd9d549661f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a5c506ab224e399b99ba3acecf4031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427ce94033f843df889e0ba258b817a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06711a453bae4337a605c36f79d25f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "043616c7eaf0436585d4217b253e263d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86abbef46a844bf5b81f9bf1caf96478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1703a431ba5442d1b88cb6bd29a28556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7896e1a320c4f9ea88af426bc1c5601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3032c1e843445e8b79e2ec576b1b49b",
              "IPY_MODEL_5735f83bda5d40ee9090f091b7012168",
              "IPY_MODEL_6d259698b5dd4fbb87f695df26929fbd"
            ],
            "layout": "IPY_MODEL_269c810f32e0499eb7ee1d7d544bfaa8"
          }
        },
        "c3032c1e843445e8b79e2ec576b1b49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9ac8816d21440db53e60c45bf06041",
            "placeholder": "​",
            "style": "IPY_MODEL_1658fd6be27d40b4bb6b8118ce80161f",
            "value": "tokenizer.json: 100%"
          }
        },
        "5735f83bda5d40ee9090f091b7012168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c0855b954f44791a45d5b5e1ef63bef",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f97e9c1099e548dea650b6f5ac80b8cf",
            "value": 2424064
          }
        },
        "6d259698b5dd4fbb87f695df26929fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b09bb08a866142ad9247d75623b1e144",
            "placeholder": "​",
            "style": "IPY_MODEL_463c39419eb44aa6b8f812a79776279d",
            "value": " 2.42M/2.42M [00:02&lt;00:00, 892kB/s]"
          }
        },
        "269c810f32e0499eb7ee1d7d544bfaa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f9ac8816d21440db53e60c45bf06041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1658fd6be27d40b4bb6b8118ce80161f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c0855b954f44791a45d5b5e1ef63bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97e9c1099e548dea650b6f5ac80b8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b09bb08a866142ad9247d75623b1e144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "463c39419eb44aa6b8f812a79776279d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinjaljoshi/s2t-training/blob/main/testing_after_react_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFx4J7n4l92B"
      },
      "outputs": [],
      "source": [
        "#connect to storage bucket\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 'llm-text-to-sql-445914'\n",
        "!gcloud config set project $PROJECT_ID"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mk0kiTYmO2k",
        "outputId": "8776ce15-7573-4fda-f062-c4759ba62b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m cp -r gs://llm-pipeline-resources/models/fine_tuned_model_v1.1 /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30VhYyJrmUPr",
        "outputId": "00e2f495-ed32-437d-835d-fb20206e0deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://llm-pipeline-resources/models/fine_tuned_model_v1.1/README.md...\n",
            "/ [0/3 files][    0.0 B/ 18.0 MiB]   0% Done                                    \rCopying gs://llm-pipeline-resources/models/fine_tuned_model_v1.1/adapter_config.json...\n",
            "Copying gs://llm-pipeline-resources/models/fine_tuned_model_v1.1/adapter_model.safetensors...\n",
            "\\ [3/3 files][ 18.0 MiB/ 18.0 MiB] 100% Done                                    \n",
            "Operation completed over 3 objects/18.0 MiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/fine_tuned_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FkWKT47nUor",
        "outputId": "46212930-7376-4b42-a10a-76f46e5a4a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3096216\n",
            "-rw-r--r-- 1 root root        709 Jan  3 00:38 adapter_config.json\n",
            "-rw-r--r-- 1 root root   18915328 Jan  3 00:38 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root        816 Jan  3 00:38 config.json\n",
            "-rw-r--r-- 1 root root        142 Jan  3 00:38 generation_config.json\n",
            "-rw-r--r-- 1 root root 3151584312 Jan  3 00:39 model.safetensors\n",
            "-rw-r--r-- 1 root root       5094 Jan  3 00:38 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
        "\n",
        "for param in base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "full_model = PeftModel.from_pretrained(base_model, \"/content/fine_tuned_model_v1.1\")\n",
        "\n",
        "# full_model = T5ForConditionalGeneration.from_pretrained(\"/content/fine_tuned_model\")\n",
        "\n",
        "trainable_params = [name for name, param in full_model.named_parameters() if param.requires_grad]\n",
        "print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "print(\"Trainable parameters:\", trainable_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "71168dc7c14a4ea499d1db1361700905",
            "331a491dca7042479e919b7b5f3d5a42",
            "ad2dc63c0c40421bbf65b1aa2e8136e1",
            "483a843f12cb4084a159b2be60e40a37",
            "19f387042f354f4baba96ae7110646bc",
            "34882878d7914f8aa292819ac626d77c",
            "c0ef0fd1ef1e4af98e0b011f72e63ff1",
            "daf622dc158c41e49ee5baa8aba6fb1e",
            "5af16e71149f4cf5b9afd27875efc6d0",
            "91c7b52578cb466e87252ff668665b3f",
            "e9d311c984b84a18b8a0df907f6ee2df",
            "6e4d5102194f46fba49f2fb2a55de465",
            "d54e62a964304dc2a34d42e09b77b3cb",
            "feaddd9ecbf84b87ac81d6b50e8030eb",
            "3c106116180b4498b880cf8f7ee543a3",
            "f67b6ba9cc5d4ec58fd2423ca86b7778",
            "deef854c9a6b4117a9dbbf65d2a443a7",
            "dfd59197cc7a4962a8ef56eab3a5e6f2",
            "a547603572c24e668dc90d044651442c",
            "ac5d22f0ed1545baa3630b3fe535ba73",
            "6e36e7e743ec48409b42a03e6a627604",
            "a1f17d11cfad4d0d8b1b184d93e87ebe",
            "3de631d9dc2543809c5b39192288102b",
            "4c07a0d3e2884d22879017fa20472799",
            "0a1a2897d8264828905ea2312260a795",
            "5c48ab044b7f47639a5b98966563974c",
            "2b9370748da145dc8eaf420c214dd543",
            "1fbe1c13231648efbf0caaaa99cb3cc9",
            "6cbf93df1f1a497e836c18b1860799ed",
            "1f98582932854d208422fb0040370dd3",
            "a8c3caa287c24ebebb859bd7b3ecd217",
            "413032f0891841d5a685232f1f6035d4",
            "9f532afdcdad4c9fad9b9e2c626a02ab"
          ]
        },
        "id": "UswVHzU8mkz_",
        "outputId": "a76ee973-9bd2-49df-8083-b8038a6c15e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71168dc7c14a4ea499d1db1361700905"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e4d5102194f46fba49f2fb2a55de465"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3de631d9dc2543809c5b39192288102b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 0\n",
            "Trainable parameters: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rRpeH-dmobEI",
        "outputId": "f8b4baab-c79c-4164-d52b-8ba95582cec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 1024)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 1024)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 16)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-23): 23 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 1024)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 16)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-23): 23 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import T5Tokenizer\n",
        "import torch\n",
        "\n",
        "# Configure the tokenizer's pad_token to be the eos_token\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as PAD token\n",
        "\n",
        "#sample_input = \"Write a SQL query to retrieve all customers who made purchases last year. TABLE CUSTOMER_PURCHASES 'contains customers and purchases' (CUSTOMER_NAME, PURCHASE_ID, PURCHASE_DATE)\"\n",
        "sample_input = \"Write a SQL query to find all customers and the total amount they spent. TABLE CUSTOMERS 'contains customer details' (CUSTOMER_ID, CUSTOMER_NAME) TABLE PURCHASES 'contains purchase details' (PURCHASE_ID, CUSTOMER_ID, AMOUNT)\"\n",
        "\n",
        "inputs = tokenizer(sample_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "# Move inputs to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "full_model.to(device)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = full_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=512,\n",
        "        num_beams=4  # Use beam search for better results\n",
        "    )\n",
        "\n",
        "# Decode and print the output\n",
        "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", decoded_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WSdaRc0ok5D",
        "outputId": "fd1ede2c-67c6-4400-ee17-69c19d35419b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: <pad> SELECT c.CUSTOMER_NAME, SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME; SELECT SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME; SELECT SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME; SELECT SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME; SELECT SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME; SELECT SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID; SELECT SUM(p.AMOUNT) AS TOTAL_PURCHASES FROM CUSTOMERS c LEFT JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = \"Write a SQL query to find the names of all customers who purchased a product in the 'Electronics' category. TABLE CUSTOMERS 'contains customer details' (CUSTOMER_ID, CUSTOMER_NAME) TABLE PURCHASES 'contains purchase details' (PURCHASE_ID, CUSTOMER_ID, PRODUCT_ID) TABLE PRODUCTS 'contains product details' (PRODUCT_ID, PRODUCT_NAME, CATEGORY)\"\n",
        "\n",
        "inputs = tokenizer(sample_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "# # Move inputs to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# full_model.to(device)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = full_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=512,\n",
        "        num_beams=4  # Use beam search for better results\n",
        "    )\n",
        "\n",
        "# Decode and print the output\n",
        "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", decoded_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y2UAA8cqdI1",
        "outputId": "a8111f66-8b2b-4153-9c72-31a899810222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: <pad> SELECT c.CUSTOMER_NAME FROM CUSTOMERS c INNER JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID INNER JOIN PRODUCTS p ON p.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Electronics'; SELECT c.CUSTOMER_NAME FROM CUSTOMERS c INNER JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID INNER JOIN PRODUCTS p ON p.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Electronics'; SELECT c.CUSTOMER_NAME FROM CUSTOMERS c INNER JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID INNER JOIN PRODUCTS p ON p.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Electronics'; SELECT c.CUSTOMER_NAME FROM CUSTOMERS c INNER JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID INNER JOIN PRODUCTS p ON p.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Electronics'; SELECT c.CUSTOMER_NAME FROM CUSTOMERS c INNER JOIN PURCHASES p ON c.CUSTOMER_ID = p.CUSTOMER_ID INNER JOIN PRODUCTS p ON p.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Electronics'; SELECT c.CUSTOMER_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_input = \"Write a SQL query to find all orders and their customer names placed after January 1, 2023. TABLE CUSTOMERS 'contains customer details' (CUSTOMER_ID 'unique customer identifier', CUSTOMER_NAME 'name of the customer') TABLE ORDERS 'contains order details' (ORDER_ID 'unique order identifier', CUSTOMER_ID 'foreign key to customers', ORDER_DATE 'date the order was placed')\"\n",
        "\n",
        "sample_input = \"What is kinjalization\"\n",
        "inputs = tokenizer(sample_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "# # Move inputs to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# full_model.to(device)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = full_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=1024,\n",
        "        num_beams=2  # Use beam search for better results\n",
        "    )\n",
        "\n",
        "# Decode and print the output\n",
        "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", decoded_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVO1h95Er2dp",
        "outputId": "9c877805-5d01-438b-a57b-6ad34e3b915b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: <pad> kinjalization is a term used to describe a process by which a group of people are grouped together in a particular way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = \"Write a SQL query to find the total revenue generated in each region. TABLE REGIONS 'contains region details' (REGION_ID 'unique region identifier', REGION_NAME 'name of the region') TABLE CUSTOMERS 'contains customer details' (CUSTOMER_ID 'unique customer identifier', REGION_ID 'foreign key to regions') TABLE ORDERS 'contains order details' (ORDER_ID 'unique order identifier', CUSTOMER_ID 'foreign key to customers', TOTAL_AMOUNT 'total amount of the order')\"\n",
        "\n",
        "inputs = tokenizer(sample_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "# # Move inputs to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# full_model.to(device)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = full_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=512,\n",
        "        num_beams=4  # Use beam search for better results\n",
        "    )\n",
        "\n",
        "# Decode and print the output\n",
        "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", decoded_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pf4DVE1sWlu",
        "outputId": "9dcd1e04-7914-4e84-b21f-24c28442d50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: <pad> SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM REGIONS r JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID JOIN ORDERS o ON c.CUSTOMER_ID = o.CUSTOMER_ID GROUP BY r.REGION_NAME; SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM REGIONS r JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID JOIN ORDERS o ON c.CUSTOMER_ID = o.CUSTOMER_ID GROUP BY r.REGION_NAME; SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM REGIONS r JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID JOIN ORDERS o ON c.CUSTOMER_ID = o.CUSTOMER_ID GROUP BY r.REGION_NAME; SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM REGIONS r JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID JOIN ORDERS o ON c.CUSTOMER_ID = o.CUSTOMER_ID GROUP BY r.REGION_NAME; SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM REGIONS r JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID; SELECT r.REG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', force=True)\n",
        "nltk.download('punkt_tab', force=True)\n",
        "print(nltk.find('tokenizers/punkt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaJaLz6Zt9ho",
        "outputId": "75e7ee32-7c45-447f-f47f-51fa8f235103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/nltk_data/tokenizers/punkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "def sliding_window_sentence_tokenize(tokenizer, text, max_length=512, stride=256):\n",
        "    \"\"\"\n",
        "    Tokenizes text using a sliding window approach, ensuring sentence boundaries are respected.\n",
        "\n",
        "    Parameters:\n",
        "        tokenizer: The T5Tokenizer instance.\n",
        "        text (str): Input text to be tokenized.\n",
        "        max_length (int): Maximum token length for each chunk.\n",
        "        stride (int): Overlap size (in tokens) between chunks.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tokenized chunks (token IDs).\n",
        "    \"\"\"\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Tokenize sentences and accumulate into chunks\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokenized_sentence = tokenizer(sentence, add_special_tokens=False)['input_ids']\n",
        "        sentence_length = len(tokenized_sentence)\n",
        "\n",
        "        # If adding the current sentence exceeds max_length, finalize the current chunk\n",
        "        if current_length + sentence_length > max_length:\n",
        "            chunks.append(current_chunk)\n",
        "            current_chunk = tokenized_sentence[-stride:]  # Start new chunk with overlap\n",
        "            current_length = len(current_chunk)\n",
        "        else:\n",
        "            current_chunk.extend(tokenized_sentence)\n",
        "            current_length += sentence_length\n",
        "\n",
        "    # Add the last chunk\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "9syXE14_tvNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
        "full_model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n4cWBKDdEA2q",
        "outputId": "806962cd-bad4-443c-903f-e1a79fe4b905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 1024)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 1024)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 16)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-23): 23 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 1024)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 16)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-23): 23 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.3, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as PAD token\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "69fd299b35a0485f9a53d023cb697397",
            "f227bba590d845b8ae0d314a94a6f033",
            "37f528be0b10428ba1abe1112eae54c9",
            "f7b768d6d27a456c96558190157cc1e0",
            "cbf65a585e3e412b9642d3cfd86e4252",
            "baebaf8d393d4035abd5184b7f061270",
            "5b80bc1ac69b4f229fd0b05b02cffc75",
            "6f5296d300f242f29abe97359930d5c6",
            "249b31f291964cdca9ea7b52e9a20b1c",
            "cdc65d8705464cd2a70b4c5415c227b9",
            "7aa42afd03054a5982725d7a09690e99",
            "8160a020a3d344099739e2ad957b751e",
            "0b1ebf747ae941f38f5096db0c13f876",
            "eae0920980344645a41ca5ccd736851a",
            "c74c1fa4de134a48b6d2fbe124aaf11b",
            "07bc1514b4cb444e89f9c053bc609d08",
            "fad7253ba3214af38c3817d91e5de1ae",
            "80aa81ad70994a2abc125eacd3cf835b",
            "164f25e4f0114219856fdc90e7b0b335",
            "d1c26f3be1c04ccaaa8448c266d796ee",
            "a18e349512f84bd5a396b307e0b18645",
            "3481ba895a5d4913a9c2a44150797ebf",
            "106fd5c0fa7b4a1c9b12b0d70c8d702b",
            "be24dcd89e7240e5a450e9675d18ea67",
            "59474c5b9c5e4cc897f824660b77b24d",
            "9a780c09d7de447cbc7389599c09f106",
            "94130dbb87794260bd7b0cd9d549661f",
            "68a5c506ab224e399b99ba3acecf4031",
            "427ce94033f843df889e0ba258b817a6",
            "06711a453bae4337a605c36f79d25f95",
            "043616c7eaf0436585d4217b253e263d",
            "86abbef46a844bf5b81f9bf1caf96478",
            "1703a431ba5442d1b88cb6bd29a28556",
            "d7896e1a320c4f9ea88af426bc1c5601",
            "c3032c1e843445e8b79e2ec576b1b49b",
            "5735f83bda5d40ee9090f091b7012168",
            "6d259698b5dd4fbb87f695df26929fbd",
            "269c810f32e0499eb7ee1d7d544bfaa8",
            "9f9ac8816d21440db53e60c45bf06041",
            "1658fd6be27d40b4bb6b8118ce80161f",
            "9c0855b954f44791a45d5b5e1ef63bef",
            "f97e9c1099e548dea650b6f5ac80b8cf",
            "b09bb08a866142ad9247d75623b1e144",
            "463c39419eb44aa6b8f812a79776279d"
          ]
        },
        "id": "KMBck1rhtnsV",
        "outputId": "0dda29e0-6900-4ea1-8140-ef8b28091aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69fd299b35a0485f9a53d023cb697397"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8160a020a3d344099739e2ad957b751e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106fd5c0fa7b4a1c9b12b0d70c8d702b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7896e1a320c4f9ea88af426bc1c5601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "max_length = 512\n",
        "stride = 256\n",
        "\n",
        "sample_input = \"Using the tables and columns provided write a single SQL query to find the names of employees who worked on projects in the 'Technology' department. TABLE EMPLOYEES 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', EMPLOYEE_NAME 'name of the employee') TABLE PROJECTS 'contains project details' (PROJECT_ID 'unique project identifier', DEPARTMENT_ID 'foreign key to departments') TABLE DEPARTMENTS 'contains department details' (DEPARTMENT_ID 'unique department identifier', DEPARTMENT_NAME 'name of the department') TABLE EMPLOYEE_PROJECTS 'tracks employees assigned to projects' (EMPLOYEE_ID 'foreign key to employees', PROJECT_ID 'foreign key to projects')\"\n",
        "\n",
        "chunks = sliding_window_sentence_tokenize(tokenizer, sample_input, max_length, stride)\n",
        "\n",
        "# # Move inputs to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# full_model.to(device)\n",
        "# inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "responses = []\n",
        "for chunk in chunks:\n",
        "  input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "# Generate output\n",
        "  with torch.no_grad():\n",
        "      outputs = full_model.generate(\n",
        "          **input_chunk,\n",
        "          max_length=256,\n",
        "          #num_beams=4  # Use beam search for better results\n",
        "          do_sample=True,  # Use sampling for more diverse outputs\n",
        "          repetition_penalty=1.2,  # Penalize repeated tokens\n",
        "          temperature=0.7,        # Add randomness\n",
        "          top_k=10,               # Use top-k sampling\n",
        "          top_p=0.9\n",
        "      )\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  responses.append(response)\n",
        "\n",
        "# Decode and print the output\n",
        "#decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", responses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s4BfJ49swDY",
        "outputId": "be27930a-7054-4c03-f5cb-a30afb788103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: [\"<pad> SELECT e.EMPLOYEE_NAME FROM EMPLOYEES e INNER JOIN EMPLOYEE_PROJECTS ep ON e.EMPLOYEE_ID = ep.EMPLOYEE_ID INNER JOIN PROJECTS p ON ep.PROJECT_ID = p.PROJECT_ID WHERE p.DEPARTMENT_NAME = 'Technology'; SELECT e.EMPLOYEE_NAME FROM EMPLOYEE_PROJECTS ep INNER JOIN EMPLOYEES e ON ep.EMPLOYEE_ID = ep.EMPLOYEE_ID WHERE p.DEPARTMENT_NAME = 'Technology'; SELECT e.EMPLOYEE_NAME FROM EMPLOYEE_PROJECTS ep INNER JOIN EMPLOYEES e ON ep.EMPLOYEE_ID = e\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512\n",
        "stride = 256\n",
        "\n",
        "sample_input = \"Write a SQL query to find all products purchased by customers in the 'North' region. TABLE REGIONS 'contains region details' (REGION_ID 'unique region identifier', REGION_NAME 'name of the region') TABLE CUSTOMERS 'contains customer details' (CUSTOMER_ID 'unique customer identifier', REGION_ID 'foreign key to regions') TABLE ORDERS 'contains order details' (ORDER_ID 'unique order identifier', CUSTOMER_ID 'foreign key to customers') TABLE ORDER_DETAILS 'tracks products in orders' (ORDER_ID 'foreign key to orders', PRODUCT_ID 'foreign key to products') TABLE PRODUCTS 'contains product details' (PRODUCT_ID 'unique product identifier', PRODUCT_NAME 'name of the product')\"\n",
        "\n",
        "chunks = sliding_window_sentence_tokenize(tokenizer, sample_input, max_length, stride)\n",
        "\n",
        "# # Move inputs to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# full_model.to(device)\n",
        "# inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "responses = []\n",
        "for chunk in chunks:\n",
        "  input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "# Generate output\n",
        "  with torch.no_grad():\n",
        "      outputs = full_model.generate(\n",
        "          **input_chunk,\n",
        "          max_length=512,\n",
        "          num_beams=4  # Use beam search for better results\n",
        "      )\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  responses.append(response)\n",
        "\n",
        "# Decode and print the output\n",
        "#decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", responses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osBzrcNevlM-",
        "outputId": "9f83104b-fdcb-4245-8f94-69897962daa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: [\"<pad> SELECT p.PRODUCT_NAME FROM REGIONS r INNER JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID INNER JOIN ORDERS o ON c.CUSTOMER_ID = o.CUSTOMER_ID INNER JOIN ORDER_DETAILS od ON o.PRODUCT_ID = od.PRODUCT_ID INNER JOIN PRODUCTS p ON od.PRODUCT_ID = p.PRODUCT_ID INNER JOIN ORDER_DETAILS odd ON od.PRODUCT_ID = odd.PRODUCT_ID INNER JOIN PRODUCTS p ON od.PRODUCT_ID = p.PRODUCT_ID WHERE r.REGION_NAME = 'North'; SELECT p.PRODUCT_NAME FROM REGIONS r INNER JOIN CUSTOMERS c ON r.REGION_ID = c.REGION_ID INNER JOIN ORDERS o ON c.CUSTOMER_ID = o.CUSTOMER_ID WHERE r.REGION_NAME = 'North'; SELECT p.PRODUCT_NAME FROM PRODUCTS p INNER JOIN ORDER_DETAILS od ON od.PRODUCT_ID = od.PRODUCT_ID WHERE od.ORDER_ID = od.ORDER_ID; SELECT p.PRODUCT_NAME FROM PRODUCTS p INNER JOIN ORDER_DETAILS od ON od.PRODUCT_ID = od.PRODUCT_ID WHERE od.ORDER_ID = od.ORDER_ID; SELECT p.PRODUCT_NAME FROM PRODUCTS p INNER JOIN ORDER_DETAILS od ON od.PRO\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512\n",
        "stride = 256\n",
        "\n",
        "sample_input = \"Write a SQL query to find the total sales for each salesperson in the 'Electronics' category. TABLE SALESPEOPLE 'contains salesperson details' (SALESPERSON_ID 'unique salesperson identifier', SALESPERSON_NAME 'name of the salesperson') TABLE ORDERS 'contains order details' (ORDER_ID 'unique order identifier', SALESPERSON_ID 'foreign key to salespeople') TABLE ORDER_DETAILS 'tracks products in orders' (ORDER_ID 'foreign key to orders', PRODUCT_ID 'foreign key to products', QUANTITY 'quantity of the product ordered') TABLE PRODUCTS 'contains product details' (PRODUCT_ID 'unique product identifier', CATEGORY 'category of the product', UNIT_PRICE 'price per unit of the product') TABLE CUSTOMERS 'contains customer details' (CUSTOMER_ID 'unique customer identifier') TABLE ORDER_CUSTOMERS 'tracks which customers placed which orders' (ORDER_ID 'foreign key to orders', CUSTOMER_ID 'foreign key to customers')\"\n",
        "\n",
        "chunks = sliding_window_sentence_tokenize(tokenizer, sample_input, max_length, stride)\n",
        "\n",
        "# # Move inputs to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# full_model.to(device)\n",
        "# inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "responses = []\n",
        "for chunk in chunks:\n",
        "  input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "# Generate output\n",
        "  with torch.no_grad():\n",
        "      outputs = full_model.generate(\n",
        "          **input_chunk,\n",
        "          max_length=512,\n",
        "          num_beams=4  # Use beam search for better results\n",
        "      )\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  responses.append(response)\n",
        "\n",
        "# Decode and print the output\n",
        "#decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Output:\", responses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3NNdnfgv4hB",
        "outputId": "00d84e0b-e11e-4e2c-d7f0-72cc19e555a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Output: [\"<pad> SELECT s.SALESPERSON_NAME, SUM(o.QUANTITY * p.UNIT_PRICE) AS TOTAL_SALE FROM SALESPEOPLE s INNER JOIN ORDERS o ON s.SALESPERSON_ID = o.SALESPERSON_ID INNER JOIN ORDER_DETAILS od ON o.ORDER_ID = od.ORDER_ID INNER JOIN PRODUCTS p ON od.PRODUCT_ID = p.PRODUCT_ID INNER JOIN CUSTOMERS c ON o.CUSTOMER_ID = c.CUSTOMER_ID INNER JOIN ORDER_CUSTOMERS oc ON c.CUSTOMER_ID = oc.CUSTOMER_ID WHERE p.CATEGORY = 'Electronics' GROUP BY s.SALESPERSON_NAME; SELECT s.SALESPERSON_NAME, SUM(o.QUANTITY * p.UNIT_PRICE) AS TOTAL_SALE FROM SALESPEOPLE s INNER JOIN ORDERS o ON s.SALESPERSON_ID = o.SALESPERSON_ID INNER JOIN ORDER_DETAILS od ON od.ORDER_ID = od.ORDER_ID INNER JOIN PRODUCTS p ON od.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Electronics' GROUP BY s.SALESPERSON_NAME; SELECT s.SALESPERSON_NAME, SUM(o.QUANTITY * p.UNIT_PRICE) AS TOTAL_SALE FROM SALESPEOPLE s INNER JOIN ORDERS o ON s.SALESPERSON_ID = o.SALESPERSON_ID INNER JOIN ORDER_DETAILS od ON od.ORDER_\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_table = [\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the salary of each employee.\",\n",
        "        \"schema\": \"TABLE rad_employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', EMPLOYEE_NAME 'name of the employee') TABLE rad_salaries 'contains salary details' (EMPLOYEE_ID 'foreign key to rad_employees', SALARY 'monthly salary of the employee')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the grades of students.\",\n",
        "        \"schema\": \"TABLE rad_students 'contains student details' (STUDENT_ID 'unique student identifier', STUDENT_NAME 'name of the student') TABLE rad_grades 'contains grade details' (STUDENT_ID 'foreign key to rad_students', GRADE 'grade awarded')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the authors of books.\",\n",
        "        \"schema\": \"TABLE rad_books 'contains book details' (BOOK_ID 'unique book identifier', BOOK_TITLE 'title of the book') TABLE rad_authors 'contains author details' (AUTHOR_ID 'unique author identifier', BOOK_ID 'foreign key to rad_books', AUTHOR_NAME 'name of the author')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the purchase date of orders.\",\n",
        "        \"schema\": \"TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', PURCHASE_DATE 'date the order was placed') TABLE rad_order_items 'tracks items in orders' (ORDER_ID 'foreign key to rad_orders', ITEM_ID 'unique item identifier', QUANTITY 'quantity of the item purchased')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find customers and their email addresses.\",\n",
        "        \"schema\": \"TABLE rad_customers 'contains customer details' (CUSTOMER_ID 'unique customer identifier', CUSTOMER_NAME 'name of the customer') TABLE rad_customer_contacts 'contains customer contact details' (CUSTOMER_ID 'foreign key to rad_customers', EMAIL 'email address of the customer')\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# SELECT e.EMPLOYEE_NAME, SUM(s.SALARY) AS TOTAL_SALARY FROM rad_employees e INNER JOIN rad_salaries s ON e.EMPLOYEE_ID = s.EMPLOYEE_ID GROUP BY e.EMPLOYEE_NAME;\n",
        "# SELECT s.STUDENT_NAME, g.GRADE FROM rad_students s LEFT JOIN rad_grades g ON s.STUDENT_ID = g.STUDENT_ID GROUP BY s.STUDENT_NAME, g.GRADE;\n",
        "# SELECT b.BOOK_TITLE, a.AUTHOR_NAME, COUNT(a.AUTHOR_ID) AS TOTAL_AUTHORS FROM rad_books b LEFT JOIN rad_authors a ON b.BOOK_ID = a.BOOK_ID GROUP BY b.BOOK_TITLE, a.AUTHOR_NAME;\n",
        "# SELECT o.ORDER_ID, o.PURCHASE_DATE, oi.QUANTITY FROM rad_orders o LEFT JOIN rad_order_items oi ON o.ORDER_ID = oi.ORDER_ID GROUP BY o.ORDER_ID, o.PURCHASE_DATE;\n",
        "# SELECT c.CUSTOMER_NAME, cc.EMAIL FROM rad_customers c LEFT JOIN rad_customer_contacts cc ON c.CUSTOMER_ID = cc.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME, cc.EMAIL;\n",
        "\n"
      ],
      "metadata": {
        "id": "3ECrsr_wxKyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "initial_text = \"Using the given tables and columns details: \"\n",
        "end_text = \".Use different table aliases for different tables in given tables\"\n",
        "prompts = [f\"{initial_text}{entry['question']}\\n{entry['schema']}{end_text}\" for entry in two_table]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SxJXNNd_xO5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bph_vTp8yqNF",
        "outputId": "56dcd27d-513f-47b1-daf2-0aa97d076f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Using the given tables and columns details: Write a SQL query to find the salary of each employee.\\nTABLE rad_employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', EMPLOYEE_NAME 'name of the employee') TABLE rad_salaries 'contains salary details' (EMPLOYEE_ID 'foreign key to rad_employees', SALARY 'monthly salary of the employee').Use different aliases for all tables\",\n",
              " \"Using the given tables and columns details: Write a SQL query to find the grades of all students.\\nTABLE rad_students 'contains student details' (STUDENT_ID 'unique student identifier', STUDENT_NAME 'name of the student') TABLE rad_grades 'contains grade details' (STUDENT_ID 'foreign key to rad_students', GRADE 'grade awarded').Use different aliases for all tables\",\n",
              " \"Using the given tables and columns details: Write a SQL query to find the authors of all books.\\nTABLE rad_books 'contains book details' (BOOK_ID 'unique book identifier', BOOK_TITLE 'title of the book') TABLE rad_authors 'contains author details' (AUTHOR_ID 'unique author identifier', BOOK_ID 'foreign key to rad_books', AUTHOR_NAME 'name of the author').Use different aliases for all tables\",\n",
              " \"Using the given tables and columns details: Write a SQL query to retrieve the purchase date of all orders.\\nTABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', PURCHASE_DATE 'date the order was placed') TABLE rad_order_items 'tracks items in orders' (ORDER_ID 'foreign key to rad_orders', ITEM_ID 'unique item identifier', QUANTITY 'quantity of the item purchased').Use different aliases for all tables\",\n",
              " \"Using the given tables and columns details: Write a SQL query to find all customers and their email addresses.\\nTABLE rad_customers 'contains customer details' (CUSTOMER_ID 'unique customer identifier', CUSTOMER_NAME 'name of the customer') TABLE rad_contacts 'contains customer contact details' (CUSTOMER_ID 'foreign key to rad_customers', EMAIL 'email address of the customer').Use different aliases for all tables\"]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "for prompt in prompts:\n",
        "  chunks = sliding_window_sentence_tokenize(tokenizer, prompt, max_length, stride)\n",
        "\n",
        "  # # Move inputs to GPU if available\n",
        "  # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # full_model.to(device)\n",
        "  # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "  responses = []\n",
        "  for chunk in chunks:\n",
        "    input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "  # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = full_model.generate(\n",
        "            **input_chunk,\n",
        "            max_length=512,\n",
        "            num_beams=5  # Use beam search for better results\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    responses.append(response)\n",
        "\n",
        "  # Decode and print the output\n",
        "  #decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  # print(\"sample_imput :\", prompt)\n",
        "  # print(\"Generated Output:\", responses)\n",
        "    if isinstance(responses, list):\n",
        "      response_text = \" \".join(responses)\n",
        "\n",
        "  match = re.search(r\"SELECT.*?;\", response_text, re.IGNORECASE | re.DOTALL)\n",
        "  print(match.group(0).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUhkvu1QytKV",
        "outputId": "23f92628-2307-4a1f-9c75-0231c00fdc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT e.EMPLOYEE_NAME, SUM(s.SALARY) AS TOTAL_SALARY FROM rad_employees e INNER JOIN rad_salaries s ON e.EMPLOYEE_ID = s.EMPLOYEE_ID GROUP BY e.EMPLOYEE_NAME;\n",
            "SELECT s.STUDENT_NAME, g.GRADE FROM rad_students s LEFT JOIN rad_grades g ON s.STUDENT_ID = g.STUDENT_ID GROUP BY s.STUDENT_NAME, g.GRADE;\n",
            "SELECT b.BOOK_TITLE, a.AUTHOR_NAME, COUNT(a.AUTHOR_ID) AS TOTAL_AUTHORS FROM rad_books b LEFT JOIN rad_authors a ON b.BOOK_ID = a.BOOK_ID GROUP BY b.BOOK_TITLE, a.AUTHOR_NAME;\n",
            "SELECT o.ORDER_ID, o.PURCHASE_DATE, oi.QUANTITY FROM rad_orders o LEFT JOIN rad_order_items oi ON o.ORDER_ID = oi.ORDER_ID GROUP BY o.ORDER_ID, o.PURCHASE_DATE;\n",
            "SELECT c.CUSTOMER_NAME, cc.EMAIL FROM rad_customers c LEFT JOIN rad_customer_contacts cc ON c.CUSTOMER_ID = cc.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME, cc.EMAIL;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\"Correct the following query - SELECT c.CUSTOMER_NAME, c.EMAIL FROM rad_customers c LEFT JOIN rad_contacts c ON c.CUSTOMER_ID = c.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME, c.EMAIL;\"]\n",
        "\n",
        "import re\n",
        "for prompt in prompts:\n",
        "  chunks = sliding_window_sentence_tokenize(tokenizer, prompt, max_length, stride)\n",
        "\n",
        "  # # Move inputs to GPU if available\n",
        "  # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # full_model.to(device)\n",
        "  # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "  responses = []\n",
        "  for chunk in chunks:\n",
        "    input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "  # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = full_model.generate(\n",
        "            **input_chunk,\n",
        "            max_length=512,\n",
        "            num_beams=4  # Use beam search for better results\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    responses.append(response)\n",
        "\n",
        "  # Decode and print the output\n",
        "  #decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  # print(\"sample_imput :\", prompt)\n",
        "  # print(\"Generated Output:\", responses)\n",
        "    if isinstance(responses, list):\n",
        "      response_text = \" \".join(responses)\n",
        "\n",
        "  match = re.search(r\"SELECT.*?;\", response_text, re.IGNORECASE | re.DOTALL)\n",
        "  print(match.group(0).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RwsFb_lxbHu",
        "outputId": "ad583a1f-3259-4e5c-d7a9-e5ec0a1e9146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.CUSTOMER_NAME, c.EMAIL FROM rad_customers c LEFT JOIN rad_contacts c ON c.CUSTOMER_ID = c.CUSTOMER_ID GROUP BY c.CUSTOMER_NAME, c.EMAIL;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_tables = [\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the total revenue generated in each region.\",\n",
        "        \"schema\": \"TABLE rad_regions 'contains region details' (REGION_ID 'unique region identifier', REGION_NAME 'name of the region') TABLE rad_customers 'contains customer details' (CUSTOMER_ID 'unique customer identifier', REGION_ID 'foreign key to rad_regions') TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', CUSTOMER_ID 'foreign key to rad_customers', TOTAL_AMOUNT 'total amount of the order')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the names of employees who worked on projects in the 'Technology' department.\",\n",
        "        \"schema\": \"TABLE rad_employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', EMPLOYEE_NAME 'name of the employee') TABLE rad_projects 'contains project details' (PROJECT_ID 'unique project identifier', DEPARTMENT_ID 'foreign key to rad_departments') TABLE rad_departments 'contains department details' (DEPARTMENT_ID 'unique department identifier', DEPARTMENT_NAME 'name of the department')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the most purchased product in each category.\",\n",
        "        \"schema\": \"TABLE rad_products 'contains product details' (PRODUCT_ID 'unique product identifier', CATEGORY 'category of the product') TABLE rad_order_details 'tracks products in orders' (ORDER_ID 'foreign key to rad_orders', PRODUCT_ID 'foreign key to rad_products', QUANTITY 'quantity of the product ordered') TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the total sales for each salesperson.\",\n",
        "        \"schema\": \"TABLE rad_salespeople 'contains salesperson details' (SALESPERSON_ID 'unique salesperson identifier', SALESPERSON_NAME 'name of the salesperson') TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', SALESPERSON_ID 'foreign key to rad_salespeople', TOTAL_AMOUNT 'total amount of the order') TABLE rad_order_details 'tracks products in orders' (ORDER_ID 'foreign key to rad_orders', PRODUCT_ID 'foreign key to rad_products', QUANTITY 'quantity of the product ordered')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to list departments with more than 10 employees.\",\n",
        "        \"schema\": \"TABLE rad_departments 'contains department details' (DEPARTMENT_ID 'unique department identifier', DEPARTMENT_NAME 'name of the department') TABLE rad_employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', DEPARTMENT_ID 'foreign key to rad_departments') TABLE rad_salaries 'contains salary details' (EMPLOYEE_ID 'foreign key to rad_employees', SALARY 'monthly salary of the employee')\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "GWnI3oVD0Jw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "initial_text = \"Using the given tables and columns details: \"\n",
        "end_text = \".Use different table names for different tables in given tables\"\n",
        "prompts = [f\"{initial_text}{entry['question']}\\n{entry['schema']}{end_text}\" for entry in three_tables]\n",
        "\n"
      ],
      "metadata": {
        "id": "sDwStsRG0T0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "  chunks = sliding_window_sentence_tokenize(tokenizer, prompt, max_length, stride)\n",
        "\n",
        "  # # Move inputs to GPU if available\n",
        "  # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # full_model.to(device)\n",
        "  # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "  responses = []\n",
        "  for chunk in chunks:\n",
        "    input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "  # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = full_model.generate(\n",
        "            **input_chunk,\n",
        "            max_length=512,\n",
        "            num_beams=5  # Use beam search for better results\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    responses.append(response)\n",
        "\n",
        "  # Decode and print the output\n",
        "  #decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  if isinstance(responses, list):\n",
        "    response_text = \" \".join(responses)\n",
        "\n",
        "  match = re.search(r\"SELECT.*?;\", response_text, re.IGNORECASE | re.DOTALL)\n",
        "  print(match.group(0).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbUKawf70IZ9",
        "outputId": "f00edba1-9124-464d-9f1c-2389cd163353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM rad_regions r INNER JOIN rad_customers c ON r.REGION_ID = c.REGION_ID INNER JOIN rad_orders o ON c.CUSTOMER_ID = o.CUSTOMER_ID GROUP BY r.REGION_NAME;\n",
            "SELECT e.EMPLOYEE_NAME FROM rad_employees e INNER JOIN rad_projects p ON e.EMPLOYEE_ID = p.EMPLOYEE_ID INNER JOIN rad_departments d ON p.DEPARTMENT_ID = d.DEPARTMENT_ID WHERE d.DEPARTMENT_NAME = 'Technology';\n",
            "SELECT p.CATEGORY, MAX(o.QUANTITY) AS MAX_PURCHASED_PRODUCT FROM rad_products p LEFT JOIN rad_order_details od ON p.PRODUCT_ID = od.PRODUCT_ID LEFT JOIN rad_orders o ON od.ORDER_ID = o.ORDER_ID GROUP BY p.CATEGORY;\n",
            "SELECT s.SALESPERSON_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_SALE FROM rad_salespeople s INNER JOIN rad_orders o ON s.SALESPERSON_ID = o.SALESPERSON_ID INNER JOIN rad_order_details od ON o.ORDER_ID = od.ORDER_ID GROUP BY s.SALESPERSON_NAME;\n",
            "SELECT d.DEPARTMENT_NAME FROM rad_departments d LEFT JOIN rad_employees e ON d.DEPARTMENT_ID = e.DEPARTMENT_ID LEFT JOIN rad_salaries s ON e.EMPLOYEE_ID = s.EMPLOYEE_ID GROUP BY d.DEPARTMENT_NAME HAVING COUNT(e.EMPLOYEE_ID) > 10;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "if isinstance(responses, list):\n",
        "  response_text = \" \".join(responses)\n",
        "\n",
        "match = re.search(r\"SELECT.*?;\", response_text, re.IGNORECASE | re.DOTALL)\n",
        "print(match.group(0).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqLRTFco4d5f",
        "outputId": "69600f0d-0fa4-45ca-dfcd-bb24b70ad09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT d.DEPARTMENT_NAME, COUNT(e.EMPLOYEE_ID) AS TOTAL_EMPLOYEES FROM rad_departments d LEFT JOIN rad_employees e ON d.DEPARTMENT_ID = e.DEPARTMENT_ID LEFT JOIN rad_salaries s ON e.EMPLOYEE_ID = s.EMPLOYEE_ID GROUP BY d.DEPARTMENT_NAME HAVING TOTAL_EMPLOYEES > 10;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "four_tables = [\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all customers who purchased electronics in the past year.\",\n",
        "        \"schema\": \"TABLE rad_customers 'contains customer details' (CUSTOMER_ID 'unique customer identifier', CUSTOMER_NAME 'name of the customer') TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', CUSTOMER_ID 'foreign key to rad_customers', ORDER_DATE 'date the order was placed') TABLE rad_order_details 'tracks products in orders' (ORDER_ID 'foreign key to rad_orders', PRODUCT_ID 'foreign key to rad_products', QUANTITY 'quantity of the product ordered') TABLE rad_products 'contains product details' (PRODUCT_ID 'unique product identifier', CATEGORY 'category of the product', PRODUCT_NAME 'name of the product')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to list all employees with salaries above $50,000 working in the 'HR' department.\",\n",
        "        \"schema\": \"TABLE rad_employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', EMPLOYEE_NAME 'name of the employee', DEPARTMENT_ID 'foreign key to rad_departments') TABLE rad_departments 'contains department details' (DEPARTMENT_ID 'unique department identifier', DEPARTMENT_NAME 'name of the department') TABLE rad_salaries 'contains salary details' (EMPLOYEE_ID 'foreign key to rad_employees', SALARY 'monthly salary of the employee') TABLE rad_projects 'contains project details' (PROJECT_ID 'unique project identifier', DEPARTMENT_ID 'foreign key to rad_departments')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find the total revenue generated by each salesperson for 'Technology' products.\",\n",
        "        \"schema\": \"TABLE rad_salespeople 'contains salesperson details' (SALESPERSON_ID 'unique salesperson identifier', SALESPERSON_NAME 'name of the salesperson') TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', SALESPERSON_ID 'foreign key to rad_salespeople') TABLE rad_order_details 'tracks products in orders' (ORDER_ID 'foreign key to rad_orders', PRODUCT_ID 'foreign key to rad_products', QUANTITY 'quantity of the product ordered') TABLE rad_products 'contains product details' (PRODUCT_ID 'unique product identifier', CATEGORY 'category of the product', UNIT_PRICE 'price per unit of the product')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to list all managers supervising more than 5 employees.\",\n",
        "        \"schema\": \"TABLE rad_employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', EMPLOYEE_NAME 'name of the employee', MANAGER_ID 'foreign key to rad_employees') TABLE rad_departments 'contains department details' (DEPARTMENT_ID 'unique department identifier', DEPARTMENT_NAME 'name of the department') TABLE rad_salaries 'contains salary details' (EMPLOYEE_ID 'foreign key to rad_employees', SALARY 'monthly salary of the employee') TABLE rad_projects 'contains project details' (PROJECT_ID 'unique project identifier', DEPARTMENT_ID 'foreign key to rad_departments')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all regions with revenue exceeding $1,000,000.\",\n",
        "        \"schema\": \"TABLE rad_regions 'contains region details' (REGION_ID 'unique region identifier', REGION_NAME 'name of the region') TABLE rad_customers 'contains customer details' (CUSTOMER_ID 'unique customer identifier', REGION_ID 'foreign key to rad_regions') TABLE rad_orders 'contains order details' (ORDER_ID 'unique order identifier', CUSTOMER_ID 'foreign key to rad_customers', TOTAL_AMOUNT 'total amount of the order') TABLE rad_order_details 'tracks products in orders' (ORDER_ID 'foreign key to rad_orders', PRODUCT_ID 'foreign key to rad_products')\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "c_YzW94o3I0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "initial_text = \"Using the given tables and columns details and foreign key relations : \"\n",
        "end_text = \".Use different table aliases for all tables\"\n",
        "prompts = [f\"{initial_text}{entry['question']}\\n{entry['schema']}{end_text}\" for entry in four_tables]\n"
      ],
      "metadata": {
        "id": "cD7RDVYV3VfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "  chunks = sliding_window_sentence_tokenize(tokenizer, prompt, max_length, stride)\n",
        "\n",
        "  # # Move inputs to GPU if available\n",
        "  # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # full_model.to(device)\n",
        "  # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "  responses = []\n",
        "  for chunk in chunks:\n",
        "    input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "  # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = full_model.generate(\n",
        "            **input_chunk,\n",
        "            max_length=512,\n",
        "            num_beams=4  # Use beam search for better results\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    responses.append(response)\n",
        "\n",
        "  # Decode and print the output\n",
        "  #decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  #print(\"Generated Output:\", responses)\n",
        "  if isinstance(responses, list):\n",
        "    response_text = \" \".join(responses)\n",
        "\n",
        "  match = re.search(r\"SELECT.*?;\", response_text, re.IGNORECASE | re.DOTALL)\n",
        "  print(match.group(0).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peVTTMeZ3h47",
        "outputId": "91f913e1-5970-4c95-8c34-0339b98bbfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.CUSTOMER_NAME FROM rad_customers c INNER JOIN rad_orders o ON c.CUSTOMER_ID = o.CUSTOMER_ID INNER JOIN rad_order_details od ON o.ORDER_ID = od.ORDER_ID INNER JOIN rad_products p ON od.PRODUCT_ID = p.PRODUCT_ID WHERE od.ORDER_DATE >= CURRENT_DATE - INTERVAL '1 year';\n",
            "SELECT e.EMPLOYEE_NAME FROM rad_employees e INNER JOIN rad_departments d ON e.DEPARTMENT_ID = d.DEPARTMENT_ID INNER JOIN rad_salaries s ON e.EMPLOYEE_ID = s.EMPLOYEE_ID INNER JOIN rad_projects p ON d.DEPARTMENT_ID = p.DEPARTMENT_ID WHERE s.SALARY > 50000 AND d.DEPARTMENT_NAME = 'HR';\n",
            "SELECT s.SALESPERSON_NAME, SUM(o.QUANTITY * p.UNIT_PRICE) AS TOTAL_REVENUE FROM rad_salespeople s INNER JOIN rad_orders o ON s.SALESPERSON_ID = o.SALESPERSON_ID INNER JOIN rad_order_details od ON o.ORDER_ID = od.ORDER_ID INNER JOIN rad_products p ON od.PRODUCT_ID = p.PRODUCT_ID WHERE p.CATEGORY = 'Technology' GROUP BY s.SALESPERSON_NAME;\n",
            "SELECT m.MANAGER_ID FROM managers m INNER JOIN rad_employees e ON m.MANAGER_ID = e.MANAGER_ID INNER JOIN rad_departments d ON e.DEPARTMENT_ID = d.DEPARTMENT_ID INNER JOIN rad_salaries s ON e.EMPLOYEE_ID = s.EMPLOYEE_ID INNER JOIN rad_projects p ON d.DEPARTMENT_ID = p.DEPARTMENT_ID GROUP BY m.MANAGER_ID HAVING COUNT(employees.EMPLOYEE_ID) > 5;\n",
            "SELECT r.REGION_NAME, SUM(o.TOTAL_AMOUNT) AS TOTAL_REVENUE FROM rad_regions r INNER JOIN rad_customers c ON r.REGION_ID = c.REGION_ID INNER JOIN rad_orders o ON c.CUSTOMER_ID = o.CUSTOMER_ID INNER JOIN rad_order_details od ON o.ORDER_ID = od.ORDER_ID WHERE o.TOTAL_AMOUNT > 1000000 GROUP BY r.REGION_NAME HAVING TOTAL_REVENUE > 1000000;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_ten_samples = [\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all customers who made purchases over $100.\",\n",
        "        \"schema\": \"TABLE customers 'contains customer details' (CUSTOMER_ID 'unique customer identifier', CUSTOMER_NAME 'name of the customer', EMAIL 'email address', PHONE 'phone number', ADDRESS 'home address', CITY 'city of residence', STATE 'state of residence', COUNTRY 'country of residence', ZIP_CODE 'postal code', REGISTRATION_DATE 'date of registration') TABLE purchases 'contains purchase details' (PURCHASE_ID 'unique purchase identifier', CUSTOMER_ID 'foreign key to customers', PRODUCT_ID 'product purchased', QUANTITY 'quantity purchased', UNIT_PRICE 'price per unit', TOTAL_AMOUNT 'total cost of the purchase', PURCHASE_DATE 'date of the purchase', PAYMENT_METHOD 'method of payment', STATUS 'status of the purchase', DISCOUNT 'discount applied')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to retrieve the names of employees and their job titles who work in the 'IT' department.\",\n",
        "        \"schema\": \"TABLE employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', FIRST_NAME 'first name of the employee', LAST_NAME 'last name of the employee', EMAIL 'email address', PHONE_NUMBER 'phone number', HIRE_DATE 'date of hire', JOB_ID 'foreign key to jobs', SALARY 'current salary', COMMISSION_PCT 'commission percentage', MANAGER_ID 'manager of the employee') TABLE jobs 'contains job details' (JOB_ID 'unique job identifier', JOB_TITLE 'title of the job', MIN_SALARY 'minimum salary for the job', MAX_SALARY 'maximum salary for the job', DEPARTMENT_ID 'foreign key to departments', LOCATION 'job location', JOB_DESCRIPTION 'description of the job', REQUIRED_SKILLS 'skills required for the job', EDUCATION_LEVEL 'required education level', EXPERIENCE 'years of experience required')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all products in stock and their supplier details.\",\n",
        "        \"schema\": \"TABLE products 'contains product details' (PRODUCT_ID 'unique product identifier', PRODUCT_NAME 'name of the product', CATEGORY 'category of the product', DESCRIPTION 'product description', UNIT_PRICE 'price per unit', QUANTITY_IN_STOCK 'quantity available in stock', REORDER_LEVEL 'minimum stock level for reorder', SUPPLIER_ID 'foreign key to suppliers', STATUS 'availability status', CREATED_AT 'date of product addition') TABLE suppliers 'contains supplier details' (SUPPLIER_ID 'unique supplier identifier', SUPPLIER_NAME 'name of the supplier', CONTACT_NAME 'contact person at supplier', PHONE 'phone number', EMAIL 'email address', ADDRESS 'business address', CITY 'city of operation', STATE 'state of operation', COUNTRY 'country of operation', POSTAL_CODE 'postal code')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to retrieve the names of students enrolled in the 'Mathematics' course.\",\n",
        "        \"schema\": \"TABLE students 'contains student details' (STUDENT_ID 'unique student identifier', FIRST_NAME 'first name of the student', LAST_NAME 'last name of the student', EMAIL 'email address', PHONE 'phone number', ENROLLMENT_DATE 'date of enrollment', PROGRAM 'academic program', YEAR 'year of study', MAJOR 'major subject', ADVISOR_ID 'academic advisor') TABLE courses 'contains course details' (COURSE_ID 'unique course identifier', COURSE_NAME 'name of the course', DEPARTMENT 'academic department offering the course', CREDITS 'number of credits for the course', INSTRUCTOR_ID 'foreign key to instructors', DESCRIPTION 'course description', PREREQUISITES 'required prerequisites for the course', SCHEDULE 'course schedule', LOCATION 'course location', MAX_ENROLLMENT 'maximum number of students allowed')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all books borrowed in the last 6 months and their borrower details.\",\n",
        "        \"schema\": \"TABLE books 'contains book details' (BOOK_ID 'unique book identifier', TITLE 'title of the book', AUTHOR 'author of the book', PUBLISHER 'publisher of the book', CATEGORY 'category of the book', LANGUAGE 'language of the book', ISBN 'ISBN number', PAGES 'number of pages', PRICE 'price of the book', AVAILABILITY 'availability status') TABLE borrowers 'contains borrower details' (BORROWER_ID 'unique borrower identifier', BORROWER_NAME 'name of the borrower', CONTACT_NUMBER 'contact number', EMAIL 'email address', MEMBERSHIP_DATE 'date of library membership', ADDRESS 'residential address', BORROW_DATE 'date the book was borrowed', RETURN_DATE 'expected return date', STATUS 'status of the borrowed book', FINE_AMOUNT 'fine amount if any')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to list all vehicles serviced in the last month and their owners' contact details.\",\n",
        "        \"schema\": \"TABLE vehicles 'contains vehicle details' (VEHICLE_ID 'unique vehicle identifier', MAKE 'manufacturer of the vehicle', MODEL 'model of the vehicle', YEAR 'year of manufacture', LICENSE_PLATE 'license plate number', OWNER_ID 'foreign key to owners', INSURANCE_STATUS 'insurance status', SERVICE_DATE 'date of last service', MILEAGE 'current mileage', STATUS 'current status of the vehicle') TABLE owners 'contains owner details' (OWNER_ID 'unique owner identifier', OWNER_NAME 'name of the vehicle owner', PHONE 'phone number', EMAIL 'email address', ADDRESS 'residential address', CITY 'city of residence', STATE 'state of residence', COUNTRY 'country of residence', ZIP_CODE 'postal code', REGISTRATION_DATE 'date of registration')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to retrieve the details of all tickets issued for speeding violations.\",\n",
        "        \"schema\": \"TABLE tickets 'contains ticket details' (TICKET_ID 'unique ticket identifier', VIOLATION_TYPE 'type of violation', VIOLATION_DATE 'date of the violation', VEHICLE_ID 'foreign key to vehicles', DRIVER_ID 'foreign key to drivers', FINE_AMOUNT 'amount of the fine', PAYMENT_STATUS 'status of the fine payment', ISSUING_OFFICER 'officer who issued the ticket', LOCATION 'location of the violation', DESCRIPTION 'additional details about the violation') TABLE drivers 'contains driver details' (DRIVER_ID 'unique driver identifier', DRIVER_NAME 'name of the driver', LICENSE_NUMBER 'driver's license number', PHONE 'contact phone number', EMAIL 'email address', ADDRESS 'residential address', CITY 'city of residence', STATE 'state of residence', COUNTRY 'country of residence', ZIP_CODE 'postal code', LICENSE_EXPIRY_DATE 'license expiration date')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all patients who visited the hospital in the past week.\",\n",
        "        \"schema\": \"TABLE patients 'contains patient details' (PATIENT_ID 'unique patient identifier', PATIENT_NAME 'name of the patient', AGE 'age of the patient', GENDER 'gender of the patient', PHONE 'contact phone number', EMAIL 'email address', ADDRESS 'residential address', CITY 'city of residence', STATE 'state of residence', ZIP_CODE 'postal code', DATE_OF_ADMISSION 'date of hospital admission') TABLE visits 'contains visit details' (VISIT_ID 'unique visit identifier', PATIENT_ID 'foreign key to patients', DOCTOR_ID 'foreign key to doctors', DATE_OF_VISIT 'date of the visit', REASON 'reason for the visit', PRESCRIPTION 'prescription details', DIAGNOSIS 'diagnosis details', FOLLOW_UP_DATE 'follow-up date if any', STATUS 'status of the visit', NOTES 'additional notes about the visit')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to list all tenants whose rent is overdue.\",\n",
        "        \"schema\": \"TABLE tenants 'contains tenant details' (TENANT_ID 'unique tenant identifier', NAME 'name of the tenant', PHONE 'contact phone number', EMAIL 'email address', LEASE_START_DATE 'start date of the lease', LEASE_END_DATE 'end date of the lease', UNIT_NUMBER 'apartment unit number', ADDRESS 'building address', CITY 'city of residence', STATE 'state of residence') TABLE rents 'contains rent payment details' (RENT_ID 'unique rent identifier', TENANT_ID 'foreign key to tenants', AMOUNT 'rent amount', DUE_DATE 'due date of the rent', PAYMENT_DATE 'date of rent payment', STATUS 'payment status', LATE_FEE 'late fee amount if any', PAYMENT_METHOD 'method of payment', TRANSACTION_ID 'transaction identifier', NOTES 'additional notes about the payment')\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Write a SQL query to find all employees who were promoted in the last 2 years.\",\n",
        "        \"schema\": \"TABLE employees 'contains employee details' (EMPLOYEE_ID 'unique employee identifier', FIRST_NAME 'first name of the employee', LAST_NAME 'last name of the employee', EMAIL 'email address', PHONE 'contact phone number', HIRE_DATE 'date of hire', DEPARTMENT_ID 'foreign key to departments', SALARY 'current salary', JOB_ID 'foreign key to jobs', STATUS 'employment status', PROMOTION_DATE 'date of last promotion') TABLE departments 'contains department details' (DEPARTMENT_ID 'unique department identifier', DEPARTMENT_NAME 'name of the department', LOCATION 'location of the department', MANAGER_ID 'manager of the department', PHONE 'department contact phone', EMAIL 'department email', BUDGET 'annual department budget', EMPLOYEE_COUNT 'number of employees in the department', CREATED_AT 'date the department was created', NOTES 'additional notes about the department')\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "_1NQLQ7q7aSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "initial_text = \"Using the given tables and columns details and foreign key relations : \"\n",
        "end_text = \".Use different table aliases for all tables and use only tables provided\"\n",
        "prompts = [f\"{initial_text}{entry['question']}\\n{entry['schema']}{end_text}\" for entry in two_ten_samples]\n"
      ],
      "metadata": {
        "id": "famVGjRm7Vhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "  chunks = sliding_window_sentence_tokenize(tokenizer, prompt, max_length, stride)\n",
        "\n",
        "  # # Move inputs to GPU if available\n",
        "  # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # full_model.to(device)\n",
        "  # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "  responses = []\n",
        "  for chunk in chunks:\n",
        "    input_chunk = {'input_ids': torch.tensor(chunk).unsqueeze(0).cuda()}\n",
        "\n",
        "  # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = full_model.generate(\n",
        "            **input_chunk,\n",
        "            max_length=512,\n",
        "            num_beams=4  # Use beam search for better results\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    responses.append(response)\n",
        "\n",
        "  # Decode and print the output\n",
        "  #decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  #print(\"Generated Output:\", responses)\n",
        "  if isinstance(responses, list):\n",
        "    response_text = \" \".join(responses)\n",
        "\n",
        "  match = re.search(r\"SELECT.*?;\", response_text, re.IGNORECASE | re.DOTALL)\n",
        "  print(match.group(0).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbCLXOtq7ZPR",
        "outputId": "afe644ae-7fea-4f47-d375-45ef238f1ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT c.CUSTOMER_NAME FROM customers c LEFT JOIN purchases p ON c.CUSTOMER_ID = p.CUSTOMER_ID WHERE p.TOTAL_AMOUNT > 100;\n",
            "SELECT e.EMPLOYEE_NAME, j.JOB_TITLE FROM employees e INNER JOIN jobs j ON e.JOB_ID = j.JOB_ID WHERE e.DEPARTMENT = 'IT';\n",
            "SELECT p.PRODUCT_NAME, s.SUPPLIER_NAME, SUM(p.QUANTITY_IN_STOCK) AS TOTAL_STOCK FROM products p LEFT JOIN suppliers s ON p.SUPPLIER_ID = s.SUPPLIER_ID WHERE p.CREATED_AT >= CURRENT_DATE - INTERVAL '1 month' GROUP BY p.PRODUCT_NAME, s.SUPPLIER_NAME;\n",
            "SELECT s.STUDENT_NAME, s.LAST_NAME FROM students s INNER JOIN courses c ON s.ENROLLMENT_DATE = c.COURSE_ID WHERE c.COURSE_NAME = 'Mathematics' GROUP BY s.STUDENT_NAME, s.LAST_NAME;\n",
            "SELECT b.BORROWER_NAME, b.TITLE, b.AUTHOR, b.PUBLISHER, b.CATEGORY, b.LANGUAGE, b.PRICE, b.AVAILABILITY FROM books b LEFT JOIN borrowers b ON b.BORROWER_ID = b.BORROWER_ID WHERE b.BORROW_DATE >= CURRENT_DATE - INTERVAL '6 MONTHS' AND b.AVAILABILITY >= CURRENT_DATE;\n",
            "SELECT v.VEHICLE_NAME, o.OWNER_NAME, o.PHONE, o.EMAIL, o.ADDRESS, o.CITY, o.STATE, o.COUNTRY, o.ZIP_CODE, o.REGISTRATION_DATE FROM vehicles v LEFT JOIN owners o ON v.OWNER_ID = o.OWNER_ID WHERE v.SERVICE_DATE >= CURRENT_DATE - INTERVAL '1 MONTH' AND v.STATUS = 'current' AND o.REGISTRATION_DATE >= CURRENT_DATE - INTERVAL '1 MONTH' GROUP BY v.VEHICLE_NAME, o.OWNER_NAME, o.PHONE, o.EMAIL, o.ADDRESS, o.CITY, o.STATE, o.COUNTRY, o. ZIP_CODE;\n",
            "SELECT d.DRIVER_NAME, t.VIOLATION_TYPE, t.VIOLATION_DATE, t.DRIVER_ID, SUM(t.FINE_AMOUNT) AS TOTAL_FINES FROM tickets t INNER JOIN drivers d ON t.DRIVER_ID = d.DRIVER_ID WHERE t.VIOLATION_TYPE = 'Speeding' GROUP BY d.DRIVER_NAME, t.VIOLATION_TYPE, t.VIOLATION_DATE;\n",
            "SELECT p.PATIENT_NAME, COUNT(v.VISIT_ID) AS TOTAL_VISITS FROM patients p INNER JOIN visits v ON p.PATIENT_ID = v.PATIENT_ID WHERE v.DATE_OF_VISIT >= CURRENT_DATE - INTERVAL '1 week' GROUP BY p.PATIENT_NAME HAVING COUNT(v.VISIT_ID) > 1;\n",
            "SELECT t.TENANT_NAME FROM tenants t LEFT JOIN rents r ON t.TENANT_ID = r.TENANT_ID WHERE r.STATUS = 'overdue';\n",
            "SELECT e.EMPLOYEE_NAME, e.LAST_NAME, e.PROMOTION_DATE FROM employees e INNER JOIN departments d ON e.DEPARTMENT_ID = d.DEPARTMENT_ID WHERE e.PROMOTION_DATE >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR) AND e.PROMOTION_DATE >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR) GROUP BY e.EMPLOYEE_NAME, e.LAST_NAME HAVING COUNT(DISTINCT e.EMPLOYEE_ID) > 1;\n"
          ]
        }
      ]
    }
  ]
}